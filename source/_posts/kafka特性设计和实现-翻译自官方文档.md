---
title: kafka特性设计和实现-翻译自官方文档
date: 2017-11-10 18:40:25
tags: kafka
---
# kafka特性设计和实现-翻译自官方文档

## 概述
kafka是最初由Linkedin公司开发，使用Scala语言编写，Kafka是一个分布式、分区的、多副本的、多订阅者的日志系统(分布式MQ系统)，它的特性如下：
- 通过**O(1)的磁盘数据结构提供消息的持久化**，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。
- 高吞吐量：即使是非常普通的硬件kafka也可以支持每秒数十万的消息。
- 支持同步和异步复制两种HA
- **Consumer客户端pull**，**随机读利用sendfile系统调用实现zero-copy** ,批量拉数据
- 消费状态保存在客户端
- 消息存储顺序写
- 数据迁移、扩容对用户透明
- 支持Hadoop并行数据加载。
- 支持online和offline的场景。
- 持久化：通过将**数据持久化到硬盘**以及**replication**防止数据丢失。
- **scale out：无需停机即可扩展机器。**
- 定期删除机制，支持设定partitions的segment file保留时间。 

## 持久性设计与性能优化
kafka在很大程度上依赖文件系统来存储和缓存消息。为了尽量缩小磁盘与内存带来的性能差异，kafka在设计上采用一些特殊设计提升性能和效率：
- kafka会保持以**顺序的方式**对硬盘进行读写（对于机械硬盘来说，随机读写带来的多余磁头寻道时间让读写速度远远慢于顺序读写）；
- 依赖于OS的**page cache（页高速缓冲存储器）**，page cache的大小为一页，通常为4K。在linux读写文件时，它用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问。详情见： [Linux Page Cache机制](https://blog.csdn.net/xf_xjtu/article/details/46382119)
- **直接在文件上进行读取和添加（append）**，这样的磁盘数据结构比起传统消息队列用的持久化数据结构如b-tree等更快，所有操作达到了O（1），并且读和写并不会互相影响。
- 为了减少字节复制，提高效率，kafka采用了**Linux下的sendfile来实现zero-copy**。现代的unix操作系统提供了一个高度优化的代码路径，用于将数据从页面缓存转移到套接字; 在Linux中，这是通过sendfile系统调用完成的。要理解sendfile的影响，了解数据从文件传输到套接字的常见数据路径非常重要： 
1.操作系统将数据从磁盘读取到内核空间的pagecache中 
2.应用程序从内核空间读取数据到用户空间缓冲区 
3.应用程序将数据写回内核空间到套接字缓冲区 
4.操作系统将数据从套接字缓冲区复制到通过网络发送的NIC缓冲区 
这显然是低效的，有四个副本和两个系统调用。使用sendfile，通过允许操作系统将数据从pagecache直接发送到网络，可以避免重新复制。所以在这个优化的路径中，只需要最终拷贝到NIC缓冲区。
- 很多时候性能瓶颈不在cpu或者磁盘，而在于网络。Kafka以高效的批处理格式支持压缩。一批消息可以压缩在一起并以这种形式发送到服务器。这批消息将以压缩格式写入，并将保持压缩在日志中，只会由消费者解压缩。Kafka支持GZIP，Snappy和LZ4压缩协议。

## 生产者(Producer)的负载均衡与数据传输优化
### 生产者负载均衡
1. producer 端的配置文件中，指定 Kafka 的 broker 信息； 
2. kafka集群中的任何一个broker，都可以向producer提供metadata信息； 
这些metadata中包含"集群中存活的servers列表"、"partitions leader列表"等信息(请参看zookeeper中的节点信息)； 
3. 当producer获取到metadata信息之后，producer将会和Topic下所有partition leader保持socket连接； 
4. 消息由producer直接通过socket发送到broker，中间不会经过任何"路由层"； 
消息被路由到哪个partition上，由producer客户端决定，比如，可以采用"random"、"key-hash"、"轮询"等，如果一个topic中有多个partitions,那么在producer端实现"消息均衡分发"是必要的；

### 生产者的数据传输优化
kafka会试图在内存中积累数据，并在一个请求中发送大批量的数据。批处理可以被配置为累加不超过固定数量的消息并且不超过某个固定的延迟限制（比如64k或10ms）。这允许发送更多字节的累积，并且在服务器上几个较大的I / O操作。这种缓冲是可配置的，并提供了一种机制来折中少量额外的延迟以获得更好的吞吐量。

## 消费者(Consumer)对于“推拉”的权衡以及处理已消费信息的优化
### push还是pull？
消费者是应该从brokers那里pull数据，还是让brokers向消费者那里push数据？这方面，kafka采用了一种更为传统的设计方式，由大多mq共享，数据从生产者推送给brokers，由消费者从brokers那里pull。一些以日志为中心的系统，如Scribe和 Apache Flume，遵循一个非常不同的推送路径，数据被push到下游。这两种方法都有优点和缺点。然而，基于推送的系统难以处理不同的消费者，因为brokers控制数据传输的速度。目标通常是消费者能够以最大可能的速度消费; 不幸的是，在推动系统中，这意味着当消费率低于生产率（本质上是拒绝服务攻击）时，消费者容易垮掉。基于pull的系统具有更好的属性，消费者消费速度只要落后就会在它可以的时候赶上。 
基于pull的系统的另一个优点是，它可以将数据发送给消费者，基于推送的系统必须选择立即发送数据，或者累积更多的数据，然后在不知道下游消费者是否能够立即处理的情况下发送。如果调整为低延迟，则这将导致一次只发送单个消息，以便传输结束被缓冲，这是浪费的。基于pull的设计修复了这个问题，因为消费者总是将所有可用的消息拉到日志中的当前位置（或达到某个可配置的最大大小）之后。所以可以获得最佳的数据流量而不会引入不必要的延迟 
但基于pull的系统的缺点是，如果brokers没有数据，消费者可能会不断发送请求来感知数据到达。为了避免这种情况，我们在我们的pull请求中有一些参数，它们允许消费者请求以“长轮询”的方式进行阻塞，等待数据到达（并且可选地等待，直到给定数量的字节可用以确保大的传输大小）。

### 已消费的信息处理
对于大多数mq，当消息被发送给消费者时，brokers要么立即在本地记录，要么等待消费者的确认。这是一个相当直观的选择，实际上对于单个机器服务器来说，不清楚这个数据可以去哪里。由于在许多消息传递系统中用于存储的数据结构规模较小，因此这也是一个实用的选择 - 由于代理知道消耗的是什么，它可以立即删除它，保持较小数据量。 
kafka处理这个不同。topic被分成一组完全有序的分区，每个分区在任何给定的时间都被每个订阅消费者组中的一个消费者消费。这意味着消费者在每个分区中的位置只是一个整数，即要消耗的下一个消息的偏移量。这使得所消耗的状态非常小，每个分区只有一个数字。这个状态可以定期检查点。这使消息确认的代价非常低。 
这个方案还有一个好处。消费者可以故意倒回到旧的偏移量并重新使用数据。这违反了队列的共同合同，但是对于许多消费者来说却是一个必不可少的特征。例如，如果消费者代码有一个错误，并且在一些消息被消费之后被发现，则消费者可以在错误修复后重新使用这些消息。

## kafka的信息传递保证
可能的信息传递保证：
- 最多一次 -消息可能会丢失，但永远不会重新发送。
- 至少一次 -消息永远不会丢失，但可以重新传递。
- 恰恰一次 - 这就是人们真正想要的，每个信息只传递一次。 
Kafka支持在KafkaStreams中一次交付，并且在Kafka topic之间传输和处理数据时，事务性生产者/消费者通常可用于提供准确一次的交付。其他目的地系统的一次交付通常需要与这些系统合作，但是Kafka提供了实现这种可行的补偿。否则，Kafka默认保证至少一次交付，并允许用户在处理一批消息之前，通过禁用生产者的重试和消费者的抵消来实现至多一次交付。